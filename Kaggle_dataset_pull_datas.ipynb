{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0f4c097-0845-4619-9be2-862a2172c596",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Renewable Energy Analysis\n",
    "* First we need to install kaggle libraries.\n",
    "* You should download kaggle API token to your computer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6652ab-84ab-4f07-9b26-a62495d35c55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting kaggle\n  Downloading kaggle-1.6.3.tar.gz (84 kB)\nRequirement already satisfied: six>=1.10 in /databricks/python3/lib/python3.9/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.9/site-packages (from kaggle) (2021.10.8)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.9/site-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from kaggle) (2.27.1)\nCollecting tqdm\n  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\nCollecting python-slugify\n  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: urllib3 in /databricks/python3/lib/python3.9/site-packages (from kaggle) (1.26.9)\nRequirement already satisfied: bleach in /databricks/python3/lib/python3.9/site-packages (from kaggle) (4.1.0)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from bleach->kaggle) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->bleach->kaggle) (3.0.4)\nCollecting text-unidecode>=1.3\n  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->kaggle) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->kaggle) (2.0.4)\nBuilding wheels for collected packages: kaggle\n  Building wheel for kaggle (setup.py): started\n  Building wheel for kaggle (setup.py): finished with status 'done'\n  Created wheel for kaggle: filename=kaggle-1.6.3-py3-none-any.whl size=111935 sha256=619b4ad3118c90ff411fa0242af7e56cc00b14dc230d7cc61b95ab03192c564a\n  Stored in directory: /root/.cache/pip/wheels/86/bc/b2/99460b4db22375a6103c397037ca1689f6cf7e51813e44452d\nSuccessfully built kaggle\nInstalling collected packages: text-unidecode, tqdm, python-slugify, kaggle\nSuccessfully installed kaggle-1.6.3 python-slugify-8.0.1 text-unidecode-1.3 tqdm-4.66.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6f26c1-0640-4a09-940d-1e575c39cffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This code is bash and inside AzureCLI\n",
    "#Locate your kaggle.json file: This is the file you downloaded from Kaggle.\n",
    "#Move kaggle.json to the Correct Directory\n",
    "mkdir -p ~/.kaggle\n",
    "cp path_to_kaggle.json ~/.kaggle/kaggle.json\n",
    "chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3d9f4d5-5ddf-4e48-acba-2ca24aec10ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#If you want to put your credentials manually, On Unix-based systems (Linux, Mac), you can set the environment variable in your terminal:\n",
    "export KAGGLE_USERNAME=your_username\n",
    "export KAGGLE_KEY=your_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51b1cea0-0102-4507-825c-730493013e2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Download dataset from Kaggle\n",
    "kaggle datasets download -d dataset-owner/dataset-name -p /path/to/download\n",
    "\n",
    "# Unzip if necessary\n",
    "unzip /path/to/download/dataset-name.zip -d /path/to/download\n",
    "\n",
    "# Upload to Azure Blob Storage\n",
    "az storage blob upload --account-name yourstorageaccount --container-name yourcontainer --file \"/path/to/download/dataset.csv\" --name \"dataset.csv\"\n",
    "\n",
    "# Clean up local files if you don't need them after upload\n",
    "rm -rf /path/to/download/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a0e6a27-89a1-4ee1-9681-0b1120228a39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "* Now your data set is in Blob Storage\n",
    "* All you need to do is clean data inside Azure Data Lake Storage and send it to Azure Synapse Studio.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Kaggle_dataset_pull_datas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
